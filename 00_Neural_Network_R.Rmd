---
title: "Neural Network"
author: "Andres Oliden"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## First Steps 
NOTE: Your data needs to be in the folder where your code is located!

```{r}
# Clear All Variables & Clear the Screen
rm(list=ls())
cat("\014")
library(dplyr)
library(readr)
# Read in the Data
c2c_training <- read_csv("C:/Users/andre/Dropbox/School/Washington/Quarter 2/513 - Cusomter Analytics/Final Project/C2C_Training.csv")
c2c_testing <- read_csv("C:/Users/andre/Dropbox/School/Washington/Quarter 2/513 - Cusomter Analytics/Final Project/C2C_Testing.csv")

c2c <-read.csv("C:/Users/andre/Dropbox/School/Washington/Quarter 2/513 - Cusomter Analytics/Final Project/Cell2Cell_Data.csv")
View(c2c)
# Among 75 variables, only selected variables that are relevant to our analysis
training_data <- c2c_training %>% select("churn","eqpdays","months","mou","recchrge","retcalls")%>% na.omit()
testing_data <- c2c_testing %>% select("churn","eqpdays","months","mou","recchrge","retcalls")%>% na.omit()


# Explore the data
summary(training_data)
summary(testing_data)
```

## Normalization
```{r}
# Normalization (min-max scaling)
total_data <- rbind(training_data, testing_data)
maxs <- apply(total_data, 2, max)
mins <- apply(total_data, 2, min)
training_data <- as.data.frame(scale(training_data, center = mins, scale = maxs - mins))
testing_data <- as.data.frame(scale(testing_data, center = mins, scale = maxs - mins))
summary(training_data)
summary(testing_data)
```

## Install Neural Network Package and "open" it (call the library)
Type "?neuralnet" for more information on the neuralnet library

```{r}
#install.packages('neuralnet')
library("neuralnet")
```


## Training and Test Data 

1) Need to Create Training Data (i.e., Estimation Data) and Test Data (i.e., Holdout Data).

```{r}

# Training data (only 5000 observations)
# Use a small portion of original training data and "shuffle" the order of the rows to get a random result
data.train <- training_data[sample(1:nrow(training_data)),][1:5000,]

View(data.train)
summary(data.train)

# Testing data 
data.test <- testing_data
View(data.test)
summary(data.test)

View(data.train)
```


## NEURAL NET MODEL 

We will run our model on the ESTIMATION Data 

```{r}
# Estimate the Neural Net

# Model 1 - hidden layer: 10*2
nn.model <- neuralnet(churn~eqpdays+months+mou+recchrge+retcalls,data=data.train, hidden=c(10,2), threshold=0.01, stepmax=1e6, act.fct = "logistic", linear.output = FALSE)

# Model 2 - hidden layer: 20
nn.model_1 <- neuralnet(churn~eqpdays+months+mou+recchrge+retcalls,data=data.train, hidden=20, threshold=0.01, stepmax=1e6, act.fct = "logistic", linear.output = FALSE)

# Lets see what properties neuralnet.fit has
summary(nn.model)
summary(nn.model_1)

#Plot the neural network
plot(nn.model)
plot(nn.model_1)
```

Step 2: Predict Churn behavior with the Neural Network

```{r}
# Predicted Probabilities
nn.prediction.props <- compute(nn.model,data.test[,2:length(data.test)])
nn.prediction.props_1 <- compute(nn.model_1,data.test[,2:length(data.test)])
View(nn.prediction.props$net.result)
summary(nn.prediction.props$net.result)


# Predicted Class (Churn vs. non-churn)
glm.prediction.class <- round(nn.prediction.props$net.result)
glm.prediction.class_1 <- round(nn.prediction.props_1$net.result)
summary(glm.prediction.class)

```

Step 3: Create Confusion Matrix allowing to judge the quality of the predictions

```{r}
# You should have already installed the package "gmodels" in our Intro_R code
library(gmodels)
ct = CrossTable(glm.prediction.class,data.test[,1],prop.r=FALSE, prop.c=FALSE,prop.t=FALSE,
           prop.chisq=FALSE,dnn = c("Predict", "Actual"))

ct1 = CrossTable(glm.prediction.class_1,data.test[,1],prop.r=FALSE, prop.c=FALSE,prop.t=FALSE,
           prop.chisq=FALSE,dnn = c("Predict", "Actual"))

tp = ct$t[2,2] # when we predict churn = 1 and the actual churn = 1 (true positive)
fp = ct$t[2,1] # when we predict churn = 1 but the actual churn = 0 (false positive)
fn = ct$t[1,2] # when we predict churn = 0 but the actual churn = 1 (false negative)

tp1 = ct1$t[2,2] # when we predict churn = 1 and the actual churn = 1 (true positive)
fp1 = ct1$t[2,1] # when we predict churn = 1 but the actual churn = 0 (false positive)
fn1 = ct1$t[1,2] # when we predict churn = 0 but the actual churn = 1 (false negative)

# churn precision rate: for all the acutal results (0 or 1), the total number of correct predicts(1)
# precision = true positive/ (true positive + false positive)
precision = tp / (tp + fp)
precision1 = tp1 / (tp1 + fp1)

# churn recall rate: when the actuall result is churn(1), the total number of correct predicts(1)
# recall = true positive/(true positive + false negative)
recall = tp / (tp + fn)
recall1 = tp1 / (tp1 + fn1)
```



